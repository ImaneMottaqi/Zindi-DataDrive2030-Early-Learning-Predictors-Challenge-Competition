{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10560\\280896822.py:2: DtypeWarning: Columns (140,172,254,257,275,306,343,358,373,374,461,635,641,642,643) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Train = pd.read_csv('Train (1).csv')\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_10560\\280896822.py:3: DtypeWarning: Columns (172,252,254,257,275,343,358,359,461,641,642,643) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Test = pd.read_csv('Test.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load files\n",
    "Train = pd.read_csv('Train (1).csv')\n",
    "Test = pd.read_csv('Test.csv')\n",
    "SampleSubmission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.insert(2, 'paid_fees_proportion', Train['pri_fees_paid_proportion'].value_counts(normalize=True)[1])\n",
    "Test.insert(2, 'paid_fees_proportion', Test['pri_fees_paid_proportion'].value_counts(normalize=True)[1])\n",
    "\n",
    "Train.insert(3, 'avg_fees_by_age', Train.groupby('child_age')['pri_fees_amount'].transform('mean'))\n",
    "Test.insert(3, 'avg_fees_by_age', Test.groupby('child_age')['pri_fees_amount'].transform('mean'))\n",
    "\n",
    "Train.insert(4, 'height', Train['child_height'] < 200)\n",
    "Test.insert(4, 'height', Test['child_height'] < 200)\n",
    "\n",
    "Train.insert(5, 'pqa_teach', Train['pqa_score_teaching'] >= 8)\n",
    "Test.insert(5, 'pqa_teach', Test['pqa_score_teaching'] >= 8)\n",
    "\n",
    "Train.insert(6, 'pqa_environment_adequate', Train['pqa_score_environment'] >= 8)\n",
    "Test.insert(6, 'pqa_environment_adequate', Test['pqa_score_environment'] >= 8)\n",
    "\n",
    "Train.insert(7, 'child_age_5', Train['child_age'] < 60)\n",
    "Test.insert(7, 'child_age_5', Test['child_age'] < 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Test.insert(loc=len(Test.columns), column='social_rating', value=social_rating)\\nTest.insert(loc=len(Test.columns), column='age_appropriate_books', value=age_appropriate_books)\\nTest.insert(loc=len(Test.columns), column='books_available', value=books_available)\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"# Créer un nouveau attribut de ratio de livres accessibles\n",
    "book_access_ratio = Train['obs_books'].apply(lambda x: 1 if x=='Yes' else 0) / 12000\n",
    "\n",
    "# Créer un nouveau attribut de source d'eau potable\n",
    "potable_water = Train['obs_water'].apply(lambda x: 1 if x=='Tap water in the building' else 0)\n",
    "\n",
    "# Créer un nouveau attribut de ratio d'accès aux matériaux\n",
    "material_access_ratio = Train['obs_accessible'].apply(lambda x: 1 if x=='Yes' else 0) / 12000\n",
    "\n",
    "# Créer un nouveau attribut de ratio d'accès à l'eau potable\n",
    "water_access_ratio = Train['obs_potable'].apply(lambda x: 1 if x=='Yes' else 0) / 12000\n",
    "\n",
    "\n",
    "# Créer un nouveau attribut de ratio d'accès à l'énergie\n",
    "energy_access_ratio = (Train['obs_heating_census'].apply(lambda x: 1 if x!='None' else 0) + \\\n",
    "                                Train['obs_cooking_census'].apply(lambda x: 1 if x!='None' else 0) + \\\n",
    "                                Train['obs_lighting_census'].apply(lambda x: 1 if x!='None' else 0)) / \\\n",
    "                               12000  \n",
    "\n",
    "Train['teacher_duration'].fillna('', inplace=True)\n",
    "\n",
    "# Define a function to create a new feature based on teacher_duration\n",
    "def experience_bins(duration):\n",
    "    if duration == '':\n",
    "        return 'no experience'\n",
    "    elif duration <= 2:\n",
    "        return 'novice'\n",
    "    elif duration <= 5:\n",
    "        return 'intermediate'\n",
    "    elif duration <= 10:\n",
    "        return 'experienced'\n",
    "    else:\n",
    "        return 'expert'\n",
    "\n",
    "\"\"\"\n",
    "def social_rating_bins(rating):\n",
    "    if np.isnan(rating):\n",
    "        return 'unknown'\n",
    "    elif rating <= 10:\n",
    "        return 'low'\n",
    "    elif rating <= 15:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "\n",
    "Train['obs_books_age'].fillna(0, inplace=True)\n",
    "\n",
    "Train['obs_books'].fillna('Unknown', inplace=True)\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "teacher_experiencee = Train['teacher_duration'].apply(lambda x: experience_bins(x))\n",
    "\n",
    "\"\"\"social_rating = Train['teacher_social_total'].apply(lambda x: social_rating_bins(x))\n",
    "\n",
    "age_appropriate_books = Train['obs_books_age'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "books_available = Train['obs_books'].map({'Yes': 1, 'No': 0, 'Unknown': -1})\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Créer un nouveau attribut de ratio de livres accessibles\n",
    "book_access_ratio = Test['obs_books'].apply(lambda x: 1 if x=='Yes' else 0) / 12000\n",
    "\n",
    "# Créer un nouveau attribut de source d'eau potable\n",
    "potable_water = Test['obs_water'].apply(lambda x: 1 if x=='Tap water in the building' else 0)\n",
    "\n",
    "# Créer un nouveau attribut de ratio d'accès aux matériaux\n",
    "material_access_ratio = Test['obs_accessible'].apply(lambda x: 1 if x=='Yes' else 0) / 12000\n",
    "\n",
    "# Créer un nouveau attribut de ratio d'accès à l'eau potable\n",
    "water_access_ratio = Test['obs_potable'].apply(lambda x: 1 if x=='Yes' else 0) / 12000\n",
    "\n",
    "# Créer un nouveau attribut de ratio d'accès à l'énergie\n",
    "energy_access_ratio = (Test['obs_heating_census'].apply(lambda x: 1 if x!='None' else 0) + \\\n",
    "                                Test['obs_cooking_census'].apply(lambda x: 1 if x!='None' else 0) + \\\n",
    "                                Test['obs_lighting_census'].apply(lambda x: 1 if x!='None' else 0)) / \\\n",
    "                               12000  \n",
    "\n",
    "teacher_experiencee = Test['teacher_duration'].apply(lambda x: experience_bins(x))\n",
    "\n",
    "\"\"\"social_rating = Test['teacher_social_total'].apply(lambda x: social_rating_bins(x))\n",
    "\n",
    "age_appropriate_books = Test['obs_books_age'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "books_available = Test['obs_books'].map({'Yes': 1, 'No': 0, 'Unknown': -1})\"\"\"\n",
    "\n",
    "\n",
    "\"\"\n",
    "# Get the index of the target attribute\n",
    "target_index = Train.columns.get_loc('target')\n",
    "\n",
    "# Insert the new attributes before the target attribute\n",
    "Train.insert(loc=target_index, column='book_access_ratio', value=book_access_ratio)\n",
    "Train.insert(loc=target_index+1, column='potable_water', value=potable_water)\n",
    "Train.insert(loc=target_index+2, column='material_access_ratio', value=material_access_ratio)\n",
    "Train.insert(loc=target_index+3, column='water_access_ratio', value=water_access_ratio)\n",
    "Train.insert(loc=target_index+4, column='energy_access_ratio', value=energy_access_ratio)\n",
    "Train.insert(loc=target_index+5, column='teacher_experience', value=teacher_experiencee)\n",
    "\"\"\"Train.insert(loc=target_index+6, column='social_rating', value=social_rating)\n",
    "Train.insert(loc=target_index+7, column='age_appropriate_books', value=age_appropriate_books)\n",
    "Train.insert(loc=target_index+8, column='books_available', value=books_available)\"\"\"\n",
    "\n",
    "\n",
    "# Insert the new attributes before the target attribute\n",
    "Test.insert(loc=len(Test.columns), column='book_access_ratio', value=book_access_ratio)\n",
    "Test.insert(loc=len(Test.columns), column='potable_water', value=potable_water)\n",
    "Test.insert(loc=len(Test.columns), column='material_access_ratio', value=material_access_ratio)\n",
    "Test.insert(loc=len(Test.columns), column='water_access_ratio', value=water_access_ratio)\n",
    "Test.insert(loc=len(Test.columns), column='energy_access_ratio', value=energy_access_ratio) \n",
    "Test.insert(loc=len(Test.columns), column='teacher_experience', value=teacher_experiencee)\n",
    "\"\"\"Test.insert(loc=len(Test.columns), column='social_rating', value=social_rating)\n",
    "Test.insert(loc=len(Test.columns), column='age_appropriate_books', value=age_appropriate_books)\n",
    "Test.insert(loc=len(Test.columns), column='books_available', value=books_available)\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 254 Class in: child_date\n",
      "There is 535 Class in: child_enrolment_date\n",
      "There is 4 Class in: child_grant\n",
      "There is 4 Class in: child_years_in_programme\n",
      "There is 4 Class in: child_observe_attentive\n",
      "There is 4 Class in: child_observe_concentrated\n",
      "There is 4 Class in: child_observe_diligent\n",
      "There is 4 Class in: child_observe_interested\n",
      "There is 2 Class in: child_gender\n",
      "There is 1018 Class in: child_dob\n",
      "There is 3 Class in: child_stunted\n",
      "There is 4 Class in: child_age_group\n",
      "There is 153 Class in: id_mn_best\n",
      "There is 10 Class in: prov_best\n",
      "There is 50 Class in: id_dc_best\n",
      "There is 50 Class in: dc_best\n",
      "There is 153 Class in: mn_best\n",
      "There is 5 Class in: pra_free_play\n",
      "There is 4 Class in: pra_free_play_outdoor\n",
      "There is 31 Class in: pra_groupings\n",
      "There is 2 Class in: pra_groupings_1\n",
      "There is 2 Class in: pra_groupings_2\n",
      "There is 2 Class in: pra_groupings_3\n",
      "There is 2 Class in: pra_groupings_4\n",
      "There is 2 Class in: pra_groupings_5\n",
      "There is 3 Class in: pra_engaged\n",
      "There is 4 Class in: pra_agency_choice\n",
      "There is 4 Class in: pra_agency_explore\n",
      "There is 4 Class in: pra_agency_questions\n",
      "There is 4 Class in: pra_agency_understand\n",
      "There is 4 Class in: pra_agency_play\n",
      "There is 4 Class in: pra_agency_learn\n",
      "There is 4 Class in: pra_agency_order\n",
      "There is 8 Class in: pra_plans\n",
      "There is 2 Class in: pra_plans_1\n",
      "There is 2 Class in: pra_plans_2\n",
      "There is 2 Class in: pra_plans_3\n",
      "There is 2 Class in: pra_plans_0\n",
      "There is 2 Class in: pra_ind\n",
      "There is 2 Class in: pri_mobile\n",
      "There is 2 Class in: pri_school\n",
      "There is 2 Class in: pri_holidays\n",
      "There is 15 Class in: pri_calc_time_open\n",
      "There is 27 Class in: pri_calc_time_close\n",
      "There is 3 Class in: pri_separate\n",
      "There is 64 Class in: pri_language\n",
      "There is 2 Class in: pri_language_1\n",
      "There is 2 Class in: pri_language_2\n",
      "There is 2 Class in: pri_language_3\n",
      "There is 2 Class in: pri_language_4\n",
      "There is 2 Class in: pri_language_5\n",
      "There is 2 Class in: pri_language_6\n",
      "There is 2 Class in: pri_language_7\n",
      "There is 2 Class in: pri_language_8\n",
      "There is 2 Class in: pri_language_9\n",
      "There is 2 Class in: pri_language_10\n",
      "There is 2 Class in: pri_language_11\n",
      "There is 2 Class in: pri_language_97\n",
      "There is 1 Class in: pri_toys\n",
      "There is 2 Class in: pri_aftercare\n",
      "There is 2 Class in: pri_fees\n",
      "There is 2 Class in: pri_fees_free\n",
      "There is 11 Class in: pri_facilities\n",
      "There is 12 Class in: pri_land\n",
      "There is 3 Class in: pri_bank\n",
      "There is 2 Class in: pri_transport\n",
      "There is 26 Class in: pri_meal\n",
      "There is 2 Class in: pri_meal_1\n",
      "There is 2 Class in: pri_meal_3\n",
      "There is 2 Class in: pri_meal_4\n",
      "There is 2 Class in: pri_meal_2\n",
      "There is 5 Class in: pri_registered_partial\n",
      "There is 5 Class in: pri_registered_programme\n",
      "There is 2 Class in: pri_registered_npo\n",
      "There is 5 Class in: pri_registered_dsd\n",
      "There is 2 Class in: pri_subsidy\n",
      "There is 2 Class in: pri_network\n",
      "There is 2 Class in: pri_attendance_usual\n",
      "There is 2 Class in: pri_precovid_attendance\n",
      "There is 3 Class in: pri_kitchen\n",
      "There is 2 Class in: pri_funding_6\n",
      "There is 2 Class in: pri_funding_7\n",
      "There is 2 Class in: pri_funding_donations\n",
      "There is 2 Class in: pri_funding_97\n",
      "There is 5 Class in: pri_attendance\n",
      "There is 2 Class in: pri_meals\n",
      "There is 4 Class in: teacher_social_peers\n",
      "There is 4 Class in: teacher_social_nonaggressive\n",
      "There is 4 Class in: teacher_social_cooperate\n",
      "There is 4 Class in: teacher_social_assistance\n",
      "There is 4 Class in: teacher_social_ideas\n",
      "There is 4 Class in: teacher_social_initiative\n",
      "There is 3 Class in: teacher_emotional_understand\n",
      "There is 3 Class in: teacher_emotional_appropriate\n",
      "There is 3 Class in: teacher_emotional_independent\n",
      "There is 3 Class in: teacher_emotional_adjust\n",
      "There is 3 Class in: teacher_emotional_confidence\n",
      "There is 3 Class in: teacher_emotional_selfstarter\n",
      "There is 467 Class in: teacher_duration\n",
      "There is 2 Class in: teacher_social_met\n",
      "There is 2 Class in: teacher_emotional_met\n",
      "There is 2 Class in: teacher_selfcare_met\n",
      "There is 2 Class in: hle_ind\n",
      "There is 2 Class in: obs_firstaid\n",
      "There is 2 Class in: obs_space\n",
      "There is 167 Class in: obs_area\n",
      "There is 2 Class in: obs_area_1\n",
      "There is 2 Class in: obs_area_2\n",
      "There is 2 Class in: obs_area_3\n",
      "There is 2 Class in: obs_area_4\n",
      "There is 2 Class in: obs_area_5\n",
      "There is 2 Class in: obs_area_6\n",
      "There is 2 Class in: obs_area_7\n",
      "There is 2 Class in: obs_area_8\n",
      "There is 2 Class in: obs_area_0\n",
      "There is 1107 Class in: obs_materials\n",
      "There is 2 Class in: obs_materials_1\n",
      "There is 2 Class in: obs_materials_2\n",
      "There is 2 Class in: obs_materials_3\n",
      "There is 2 Class in: obs_materials_4\n",
      "There is 2 Class in: obs_materials_5\n",
      "There is 2 Class in: obs_materials_6\n",
      "There is 2 Class in: obs_materials_7\n",
      "There is 2 Class in: obs_materials_8\n",
      "There is 2 Class in: obs_materials_9\n",
      "There is 2 Class in: obs_materials_10\n",
      "There is 2 Class in: obs_materials_11\n",
      "There is 2 Class in: obs_materials_12\n",
      "There is 2 Class in: obs_materials_13\n",
      "There is 2 Class in: obs_materials_14\n",
      "There is 2 Class in: obs_materials_15\n",
      "There is 2 Class in: obs_materials_16\n",
      "There is 2 Class in: obs_materials_17\n",
      "There is 2 Class in: obs_materials_18\n",
      "There is 2 Class in: obs_materials_19\n",
      "There is 2 Class in: obs_materials_20\n",
      "There is 2 Class in: obs_materials_97\n",
      "There is 2 Class in: obs_materials_0\n",
      "There is 2 Class in: obs_accessible\n",
      "There is 2 Class in: obs_books\n",
      "There is 2 Class in: obs_books_age\n",
      "There is 7 Class in: obs_heating_census\n",
      "There is 7 Class in: obs_lighting_census\n",
      "There is 6 Class in: obs_cooking_census\n",
      "There is 7 Class in: obs_water\n",
      "There is 2 Class in: obs_potable\n",
      "There is 15 Class in: obs_handwashing\n",
      "There is 2 Class in: obs_handwashing_1\n",
      "There is 2 Class in: obs_handwashing_2\n",
      "There is 2 Class in: obs_handwashing_3\n",
      "There is 2 Class in: obs_handwashing_0\n",
      "There is 2 Class in: obs_handwashing_97\n",
      "There is 46 Class in: obs_toilet\n",
      "There is 2 Class in: obs_toilet_1\n",
      "There is 2 Class in: obs_toilet_2\n",
      "There is 2 Class in: obs_toilet_3\n",
      "There is 2 Class in: obs_toilet_4\n",
      "There is 2 Class in: obs_toilet_5\n",
      "There is 2 Class in: obs_toilet_6\n",
      "There is 2 Class in: obs_toilet_7\n",
      "There is 2 Class in: obs_toilet_8\n",
      "There is 2 Class in: obs_toilet_0\n",
      "There is 2 Class in: obs_toilet_97\n",
      "There is 2 Class in: obs_toilets_children\n",
      "There is 2 Class in: obs_toilets_gender\n",
      "There is 5 Class in: obs_building\n",
      "There is 2 Class in: obs_shared\n",
      "There is 2 Class in: obs_outdoor\n",
      "There is 28 Class in: obs_equipment\n",
      "There is 2 Class in: obs_equipment_0\n",
      "There is 2 Class in: obs_equipment_1\n",
      "There is 2 Class in: obs_equipment_2\n",
      "There is 2 Class in: obs_equipment_3\n",
      "There is 2 Class in: obs_equipment_4\n",
      "There is 2 Class in: obs_equipment_5\n",
      "There is 2 Class in: obs_equipment__1\n",
      "There is 4 Class in: obs_condition_equipment\n",
      "There is 2 Class in: obs_fence\n",
      "There is 2 Class in: obs_gate\n",
      "There is 2 Class in: obs_access\n",
      "There is 2 Class in: obs_water_running\n",
      "There is 9 Class in: id_prov\n",
      "There is 3 Class in: grade_r\n",
      "There is 2 Class in: professionals_practitioners\n",
      "There is 3 Class in: certificate_registration_partial\n",
      "There is 3 Class in: certificate_registration_program\n",
      "There is 3 Class in: certificate_registration_npo\n",
      "There is 3 Class in: certificate_register\n",
      "There is 2 Class in: census\n",
      "There is 2 Class in: urban\n",
      "There is 4 Class in: phase_natemis\n",
      "There is 12 Class in: language_child\n",
      "There is 13 Class in: language_assessment\n",
      "There is 4 Class in: facility_type\n",
      "There is 2 Class in: sef_ind\n",
      "There is 2 Class in: elp_ind\n",
      "There is 2 Class in: gps_ind\n",
      "There is 2 Class in: pre_covid\n",
      "There is 2 Class in: quintile_used\n",
      "There is 5 Class in: ses_cat\n",
      "There is 4 Class in: teacher_experience\n",
      "----------------------------------\n",
      "We have 289 features\n",
      "We have 201 categorical features\n",
      "We have 401 features that have more than 6000 of missing values\n"
     ]
    }
   ],
   "source": [
    "features = []; cat_features = []; not_features = []\n",
    "for k in Train.columns[1:]:\n",
    "    if Train[k].isnull().sum() < 6000:\n",
    "        features.append(k)\n",
    "        if Train[k].dtype == 'O':\n",
    "            cat_features.append(k)\n",
    "            print('There is '+ str(len(Train[k].value_counts()))+' Class in: ' +k)\n",
    "    else:\n",
    "        not_features.append(k)\n",
    "\n",
    "print('----------------------------------')\n",
    "print('We have '+str(len(features)) + ' features')\n",
    "print('We have '+str(len(cat_features)) + ' categorical features')\n",
    "print('We have '+str(len(not_features)) + ' features that have more than 6000 of missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Train = Train[features]\n",
    "Test  = Test[features[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = Train.fillna('')\n",
    "Test  = Test.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96.80999755859376, 6.369999885559082)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Train['target']), min(Train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(\n",
    "    Train[Train.columns[:-1]],\n",
    "    Train[Train.columns[-1]],\n",
    "    test_size = 0.15,\n",
    "    random_state = 42,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7297, 288), (1288, 288), (7297,), (1288,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape, xvalid.shape, ytrain.shape, yvalid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Invalid type for cat_feature[non-default value idx=5,feature_idx=123]=0.0 : cat_features must be integer or string, real number values and NaN values should be converted to string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_id_object_bytes_string_representation\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: bad object for id: 0.0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10560\\3267647627.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mxtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_dataset\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m         \u001b[1;33m=\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_best_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m    790\u001b[0m                     )\n\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m                 self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[0;32m    793\u001b[0m                            group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[0;32m    794\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hp\\anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_init\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_tags\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1418\u001b[0m             \u001b[0mfeature_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_transform_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_tags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1419\u001b[1;33m         self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[0;32m   1420\u001b[0m                         group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: Invalid type for cat_feature[non-default value idx=5,feature_idx=123]=0.0 : cat_features must be integer or string, real number values and NaN values should be converted to string."
     ]
    }
   ],
   "source": [
    "xtest = Test[features[:-1]]\n",
    "train_dataset = Pool(data = xtrain, label = ytrain, cat_features=cat_features)\n",
    "val_dataset   = Pool(data = xvalid, label = yvalid, cat_features=cat_features)\n",
    "model         = CatBoostRegressor(iterations = 30000, learning_rate=0.1, random_seed=123, verbose=300)\n",
    "model.fit(train_dataset, eval_set=val_dataset, use_best_model=True, early_stopping_rounds=300)\n",
    "preds_valid = model.predict(xvalid)\n",
    "preds_test  = model.predict(xtest)\n",
    "print(np.sqrt(mean_squared_error(yvalid, preds_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
